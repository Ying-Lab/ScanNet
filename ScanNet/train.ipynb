{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import f1_score\n",
    "import datetime\n",
    "import argparse,copy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import  DataLoader\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from sklearn.manifold import TSNE\n",
    "import torch.utils.data as Data\n",
    "\n",
    "import warnings\n",
    "import sklearn.exceptions\n",
    "warnings.filterwarnings(\"ignore\", category=sklearn.exceptions.UndefinedMetricWarning)\n",
    "\n",
    "import time\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/lyy/ScanNet')\n",
    "from scannet import *\n",
    "from datasets import GCNDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='description of')\n",
    "parser.add_argument('--dataset', default='baron_mouse', type=str)\n",
    "parser.add_argument('--cross_protocol', default=False, type=bool)\n",
    "parser.add_argument('--lr', default=0.01, type=float, help='Initial learning rate')\n",
    "parser.add_argument('--weight_decay', default=5e-4, type=float, help='Weight decay (L2 loss on parameters)')\n",
    "parser.add_argument('--type_att_size', default=32, type=int, help='type attention parameter dimension')\n",
    "parser.add_argument('--type_fusion', default='att', type=str, help='fusion method')\n",
    "parser.add_argument('--cuda', default=True, type=bool, help='cpu or gpu') #action='store_true',\n",
    "parser.add_argument('--epochs', default=60, type=int, help='Number of epoch')\n",
    "parser.add_argument('--batch_size', default=64, type=int, help='Number of batch size')\n",
    "parser.add_argument('--in_dim', default=1, type=int, help='dim of input')\n",
    "parser.add_argument('--l_dim', default=32, type=int, help='dim of GUnet')\n",
    "parser.add_argument('--h_dim', default=32, type=int, help='dim of graph')\n",
    "parser.add_argument('--l_num', default=3, type=int, help='# of GCN layer')\n",
    "parser.add_argument('--drop_p', default=0.3, type=float, help='probability of dropout')\n",
    "parser.add_argument('--weight_sample', default=False, type=bool, help='wheather sample weighted')\n",
    "args = parser.parse_args(args=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.cuda and torch.cuda.is_available():\n",
    "        device=torch.device('cuda')\n",
    "else:\n",
    "        device=torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadbench(dataset):\n",
    "    data_dir='/home/lyy/data/pbmcbench/data_pbmcbench.csv'\n",
    "    data=pd.read_csv(data_dir,index_col=0,header=0)\n",
    "    train_df=data[data['protocol'].isin(dataset.split('+'))]\n",
    "    test_df=data[~data['protocol'].isin(dataset.split('+'))]\n",
    "    adj_tf_gene=pd.read_csv('/home/lyy/data/pbmcbench/cpmadj_tf_gene.csv',index_col=0,header=0)\n",
    "    tf_num=adj_tf_gene.shape[0]\n",
    "    gene_num=adj_tf_gene.shape[1]\n",
    "    adj_tf_gene=torch.tensor(adj_tf_gene.values,dtype=torch.float32)\n",
    "    test_tf=test_df.iloc[:,:tf_num].values\n",
    "    test_gene=test_df.iloc[:,tf_num:tf_num+gene_num].values\n",
    "    label_test=torch.tensor(test_df['cell_type_label'].values,dtype=torch.int64)\n",
    "    ft_dict_test=[]\n",
    "    for i in range(test_tf.shape[0]):\n",
    "        ft_dict={'tf':torch.tensor(test_tf[i].reshape(-1,1),dtype=torch.float32),'gene':torch.tensor(test_gene[i].reshape(-1,1),dtype=torch.float32)}\n",
    "        ft_dict_test.append(ft_dict)\n",
    "    train_tf=train_df.iloc[:,:tf_num].values\n",
    "    train_gene=train_df.iloc[:,tf_num:tf_num+gene_num].values\n",
    "    label_sup=torch.tensor(train_df['cell_type_label'].values,dtype=torch.int64)\n",
    "    ft_dict_sup=[]\n",
    "    for i in range(train_tf.shape[0]):\n",
    "        ft_dict={'tf':torch.tensor(train_tf[i].reshape(-1,1),dtype=torch.float32),'gene':torch.tensor(train_gene[i].reshape(-1,1),dtype=torch.float32)}\n",
    "        ft_dict_sup.append(ft_dict)\n",
    "    ft_dict_train,ft_dict_valid,label_train,label_valid = train_test_split(ft_dict_sup,label_sup,test_size=0.2,random_state=42,stratify=label_sup) \n",
    "    return ft_dict_train,ft_dict_valid,ft_dict_test,label_train,label_valid,label_test,adj_tf_gene\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not args.cross_protocol:\n",
    "    load_path='/home/lyy/data/{}/cpm/'.format(args.dataset)\n",
    "    # ft_dict_list=torch.load('/home/lyy/data/pbmc/ATAC/ft_dict_list.pt')\n",
    "    ft_dict_list=torch.load(load_path+'logft_dict_list.pt')\n",
    "    label=torch.load(load_path+'label.pt')\n",
    "    adj_tf_gene=torch.load(load_path+'cpmadj_tf_gene.pt')\n",
    "    ft_dict_sup,ft_dict_test,label_sup,label_test = train_test_split(ft_dict_list,label,test_size=0.3,random_state=42,stratify=label)\n",
    "    ft_dict_train,ft_dict_valid,label_train,label_valid = train_test_split(ft_dict_sup,label_sup,test_size=0.2,random_state=42,stratify=label_sup) \n",
    "else:\n",
    "    ft_dict_train,ft_dict_valid,ft_dict_test,label_train,label_valid,label_test,adj_tf_gene=loadbench(args.dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获得初始化的adj_dict\n",
    "adj_dict={'tf':None,'gene':None}\n",
    "adj_gene_tf=adj_tf_gene.T\n",
    "\n",
    "degree_tf=torch.abs(adj_tf_gene).sum(dim=1)\n",
    "degree_tf_inv=torch.pow(degree_tf, -0.5)\n",
    "degree_gene=torch.abs(adj_tf_gene).sum(dim=0)\n",
    "degree_gene_inv=torch.pow(degree_gene, -0.5)\n",
    "D_tf_inv=torch.diag_embed(degree_tf_inv)\n",
    "D_gene_inv=torch.diag_embed(degree_gene_inv)\n",
    "adj_dict['tf']=torch.matmul(torch.matmul(D_tf_inv,adj_tf_gene),D_gene_inv)\n",
    "\n",
    "adj_dict['gene']=adj_dict['tf'].t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_elements = torch.unique(label_test,return_inverse=False)\n",
    "args.class_num=len(unique_elements)\n",
    "# data load\n",
    "dataset={'train':None,'valid':None,'test':None}\n",
    "dataset['train']=GCNDataset(args,ft_dict_train,label_train)\n",
    "dataset['valid']=GCNDataset(args,ft_dict_valid,label_valid)\n",
    "\n",
    "dataloader={'train':None,'valid':None,'test':None}\n",
    "dataloader['train']=DataLoader(dataset['train'],batch_size=args.batch_size,shuffle=True,pin_memory=True)\n",
    "dataloader['valid']=DataLoader(dataset['valid'],batch_size=args.batch_size,shuffle=True,pin_memory=True)\n",
    "args.train_size=label_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model and optimizer\n",
    "net_schema = {'tf':['gene'],'gene':['tf']}\n",
    "type_nodes={'tf':len(ft_dict_test[0]['tf']),'gene':len(ft_dict_test[0]['gene'])}\n",
    "all_nodes=len(ft_dict_test[0]['tf'])+len(ft_dict_test[0]['gene'])\n",
    "tf_nodes=len(ft_dict_test[0]['tf'])\n",
    "layer_shape=[args.in_dim,8,16,32,args.class_num]\n",
    "model = ScanNet(\n",
    "            net_schema=net_schema,\n",
    "            layer_shape=layer_shape,\n",
    "            all_nodes=all_nodes,\n",
    "            tf_nodes=tf_nodes,\n",
    "            type_fusion=args.type_fusion,\n",
    "            type_att_size=args.type_att_size,\n",
    "            )\n",
    "model=model.to(device)\n",
    "optimizer = optim.SGD(model.parameters(), momentum=0.9, lr= args.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_step = 0\n",
    "decay = 0.95\n",
    "decay_steps = args.train_size\n",
    "def adjust_learning_rate(optimizer, lr):\n",
    "    lr = lr * pow( decay , float(global_step// decay_steps) ) # decay by one epoch\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "    return lr\n",
    "\n",
    "best_val_acc = float(0) \n",
    "best_model_weights = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train() \n",
    "    total_loss = 0    \n",
    "    all_labels=[]\n",
    "    all_predictions=[]\n",
    "    for k in adj_dict.keys():\n",
    "        adj_dict[k]=adj_dict[k].to(device)\n",
    "    global global_step,best_val_acc,best_model_weights\n",
    "    cur_lr = adjust_learning_rate(optimizer, args.lr)\n",
    "    \n",
    "    for i,imbalanced_batch in enumerate(dataloader['train']):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        im_ft_dict,im_label=imbalanced_batch\n",
    "        for k in im_ft_dict.keys():\n",
    "            im_ft_dict[k] = im_ft_dict[k].to(device)\n",
    "\n",
    "        im_label=im_label.to(device)\n",
    "        ft=torch.cat((im_ft_dict['tf'],im_ft_dict['gene']),dim=1)\n",
    "        ft=ft.squeeze(2)\n",
    "\n",
    "        logits,gnn_re,cell_embd=model(im_ft_dict,adj_dict)\n",
    "\n",
    "        loss=model.loss(gnn_re,ft,logits,im_label,args,cell_embd)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss = total_loss + loss.item()\n",
    "        global_step += args.batch_size \n",
    "\n",
    "\n",
    "        all_labels.extend(im_label.detach().cpu().numpy())\n",
    "        all_predictions.extend(F.softmax(logits,-1).detach().cpu().numpy())\n",
    "\n",
    "    \n",
    "    epoch_loss_train=total_loss/len(dataloader['train'])\n",
    "    train_labels = np.array(all_labels)    \n",
    "    train_predictions = np.argmax(np.array(all_predictions),axis=1)\n",
    "\n",
    "    model.eval()  \n",
    "    with torch.no_grad():    \n",
    "        total_loss_val = 0\n",
    "        val_labels = []\n",
    "        val_predictions = []    \n",
    "        for i, batch in enumerate(dataloader['valid']): \n",
    "            ft_dict,label=batch\n",
    "            for k in ft_dict.keys():\n",
    "                ft_dict[k] = ft_dict[k].to(device)\n",
    "            label=label.to(device)\n",
    "            ft=torch.cat((ft_dict['tf'],ft_dict['gene']),dim=1)\n",
    "            ft=ft.squeeze(2)\n",
    "\n",
    "            logits,gnn_re,cell_embd=model(ft_dict,adj_dict)\n",
    "            \n",
    "            loss=model.loss(gnn_re,ft,logits,label,args,cell_embd)      \n",
    "\n",
    "            total_loss_val = total_loss_val + loss.item()\n",
    "\n",
    "            val_labels.extend(label.cpu().numpy())\n",
    "            val_predictions.extend(F.softmax(logits,-1).detach().cpu().numpy())\n",
    "    \n",
    "    epoch_loss_val=total_loss_val/len(dataloader['valid'])\n",
    "    val_labels = np.array(val_labels)    \n",
    "    val_predictions = np.argmax(np.array(val_predictions),axis=1)\n",
    "\n",
    "    accuracy_val = accuracy_score(val_labels, val_predictions)\n",
    "    f1_macro_val = f1_score(val_labels, val_predictions, average='macro')\n",
    "\n",
    "    if accuracy_val>best_val_acc:\n",
    "        best_val_acc=accuracy_val\n",
    "        best_model_weights=model.state_dict()  # save model weight\n",
    "\n",
    "    return epoch_loss_train,epoch_loss_val,accuracy_val,f1_macro_val,cur_lr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test(loader):\n",
    "#     model.eval()  \n",
    "#     total_loss = 0\n",
    "#     all_labels = []\n",
    "#     all_predictions = []\n",
    "#     for k in adj_dict.keys():\n",
    "#         adj_dict[k]=adj_dict[k].to(device)\n",
    "#     with torch.no_grad():        \n",
    "#         for i, batch in enumerate(loader): \n",
    "#             ft_dict,label=batch\n",
    "\n",
    "#             for k in ft_dict.keys():\n",
    "#                 ft_dict[k] = ft_dict[k].to(device)\n",
    "#             label=label.to(device)\n",
    "\n",
    "#             predictions,output_re,cell_embd=model(ft_dict,adj_dict)\n",
    "#             ft=torch.cat((ft_dict['tf'],ft_dict['gene']),dim=1)\n",
    "#             ft=ft.squeeze(2)\n",
    "\n",
    "#             loss=model.loss(output_re,ft,predictions,label,args,cell_embd)         \n",
    "\n",
    "#             total_loss = total_loss + loss.item()\n",
    "\n",
    "#             all_labels.extend(label.cpu().numpy())\n",
    "#             all_predictions.extend(predictions.cpu().numpy())\n",
    "            \n",
    "    \n",
    "    \n",
    "#     epoch_loss=total_loss/len(dataloader['valid'])\n",
    "#     test_labels = np.array(all_labels)    \n",
    "#     test_predictions = np.argmax(np.array(all_predictions),axis=1)\n",
    "\n",
    "#     accuracy1 = accuracy_score(test_labels, test_predictions)\n",
    "#     f1_macro1 = f1_score(test_labels, test_predictions, average='macro')\n",
    "    \n",
    "#     return epoch_loss,accuracy1,f1_macro1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## train\n",
    "train_loss_list=[]\n",
    "val_loss_list=[]\n",
    "val_acc_list=[]\n",
    "val_f1_list=[]\n",
    "for epoch in range(args.epochs):\n",
    "    train_loss,val_loss,val_acc,val_f1,cur_lr=train()\n",
    "    train_loss_list.append(train_loss)\n",
    "    val_loss_list.append(val_loss)\n",
    "    val_acc_list.append(val_acc)\n",
    "    val_f1_list.append(val_f1)\n",
    "    if epoch%5 == 0:\n",
    "        print('train loss:',train_loss,'valid loss:',val_loss,'acc:',val_acc,'f1_macro:',val_f1,'learning rate:',cur_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "dataset['test']=GCNDataset(args,ft_dict_test,label_test)\n",
    "dataloader['test']=DataLoader(dataset['test'],batch_size=args.batch_size,shuffle=False,pin_memory=True)\n",
    "\n",
    "model.eval() \n",
    "all_cell_embd=[] \n",
    "all_tf_embd=[]\n",
    "all_tg_embd=[]\n",
    "all_labels=[]\n",
    "all_predictions=[]\n",
    "for k in adj_dict.keys():\n",
    "        adj_dict[k]=adj_dict[k].to(device)\n",
    "with torch.no_grad():        \n",
    "    for i, batch in enumerate(dataloader['test']):\n",
    "        ft_dict,label=batch  \n",
    "        for k in ft_dict.keys():\n",
    "            ft_dict[k] = ft_dict[k].to(device)\n",
    "        for k in adj_dict.keys():\n",
    "            adj_dict[k] = adj_dict[k].to(device)\n",
    "        label=label.to(device)\n",
    "\n",
    "        logits,output_re,cell_embd=model(ft_dict,adj_dict)\n",
    "\n",
    "        all_cell_embd.extend(cell_embd.cpu().numpy())   \n",
    "        all_labels.extend(label.squeeze().detach().cpu().numpy())\n",
    "        all_predictions.extend(F.softmax(logits,-1).detach().cpu().numpy())\n",
    "\n",
    "test_labels=np.array(all_labels)\n",
    "test_pred = np.argmax(np.array(all_predictions),axis=1)\n",
    "test_predictions=np.array(all_predictions)\n",
    "test_embd=np.array(all_cell_embd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score, f1_score, precision_score, recall_score\n",
    "\n",
    "def evaluate(y_true,y_pred,y_score):\n",
    "    f1_macro1 = f1_score(y_true, y_pred, average='macro')\n",
    "    precision = precision_score(y_true, y_pred,average='macro')\n",
    "    recall = recall_score(y_true, y_pred,average='macro')\n",
    "    # 计算AUPRC\n",
    "    auprc = average_precision_score(y_true, y_score)\n",
    "    print(\"f1:{:.4f}, precision:{:.4f},recall:{:.4f}, AUPRC:{:.4f}\".format(f1_macro1,precision,recall,auprc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(test_labels,test_pred,test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "import os\n",
    "path='./results/{}/'.format(args.dataset)\n",
    "os.makedirs(path,exist_ok=True)\n",
    "string='ScanNet_{}'.format(datetime.datetime.now().strftime('%Y%m%d_%H%M'))\n",
    "save_dir=path+'{}'.format(string)\n",
    "print(save_dir)\n",
    "os.makedirs(save_dir,exist_ok=True)\n",
    "torch.save(model.state_dict(), os.path.join(save_dir,'{}.pth'.format(string)))\n",
    "np.save(os.path.join(save_dir,'train_loss.npy'),train_loss_list)\n",
    "np.save(os.path.join(save_dir,'val_loss.npy'),val_loss_list)\n",
    "np.save(os.path.join(save_dir,'val_acc.npy'),val_acc_list)\n",
    "np.save(os.path.join(save_dir,'val_f1_macro.npy'),val_f1_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GCN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
